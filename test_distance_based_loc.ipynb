{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571751c-1de1-41ed-9c99-df0c142d8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from iterative_ensemble_smoother.esmda import ESMDA\n",
    "from iterative_ensemble_smoother.experimental import DistanceESMDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52439e7b-81be-4654-ba71-c8801fc68f12",
   "metadata": {},
   "source": [
    "# 1D Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16fb8e2-3e19-4a8e-a340-4098843ab1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System properties\n",
    "N_m = 100  # Number of model parameters (grid points)\n",
    "N_e = 50  # Ensemble size\n",
    "j_obs = 50  # Index of the single observation\n",
    "N_d = 1  # Number of observations\n",
    "\n",
    "# Assimilation properties\n",
    "alpha_i = 1  # Single iteration of ES-MDA\n",
    "obs_error_var = 0.01  # Variance of observation error\n",
    "SEED = 42\n",
    "\n",
    "# Define the \"true\" model parameters\n",
    "true_parameters = np.zeros(N_m)\n",
    "\n",
    "# Define the \"true\" observation vector\n",
    "true_observations = np.array([1.0])\n",
    "\n",
    "# Observation error covariance `C_D`.\n",
    "# Since N_d=1, it's a 1-element vector.\n",
    "C_D = np.array([obs_error_var])\n",
    "\n",
    "# Generate Initial Ensemble and Predictions\n",
    "\n",
    "# Create initial ensemble of parameters `X` (prior)\n",
    "# Shape: (N_m, N_e)\n",
    "rng = np.random.default_rng(SEED)\n",
    "X_initial = rng.normal(loc=0.0, scale=0.5, size=(N_m, N_e))\n",
    "\n",
    "# Predict observations `Y` using the identity model\n",
    "# `Y = g(x) = x`\n",
    "# We only observe the state at location `j_obs`.\n",
    "# Shape: (N_d, N_e)\n",
    "Y = X_initial[[j_obs], :]\n",
    "\n",
    "\n",
    "# Construct Localization, Covariance, and Smoother\n",
    "\n",
    "# Localization matrix `rho`\n",
    "# Shape: (N_m, N_d)\n",
    "localization_radius = 10.0\n",
    "model_grid = np.arange(N_m)\n",
    "distances = np.abs(model_grid - j_obs)\n",
    "# Using a simple Gaussian decay for rho\n",
    "rho = np.exp(-0.5 * (distances / localization_radius) ** 2).reshape(-1, 1)\n",
    "\n",
    "smoother = DistanceESMDA(\n",
    "    covariance=C_D, observations=true_observations, alpha=alpha_i, seed=SEED\n",
    ")\n",
    "smoother_ESMDA = ESMDA(\n",
    "    covariance=C_D, observations=true_observations, alpha=alpha_i, seed=SEED\n",
    ")\n",
    "\n",
    "D = smoother.perturb_observations(ensemble_size=N_e, alpha=alpha_i)\n",
    "\n",
    "# Run Assimilation and Analyze\n",
    "\n",
    "# Run the assimilation\n",
    "X_posterior = smoother.assimilate(X=X_initial, Y=Y, rho=rho)\n",
    "X_posterior_ESMDA = smoother_ESMDA.assimilate(X=X_initial, Y=Y)\n",
    "\n",
    "# Calculate the mean of the prior and posterior ensembles\n",
    "prior_mean = np.mean(X_initial, axis=1)\n",
    "posterior_mean = np.mean(X_posterior, axis=1)\n",
    "posterior_mean_ESMDA = np.mean(X_posterior_ESMDA, axis=1)\n",
    "\n",
    "# Plot the Results\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Plot 1: Ensemble means\n",
    "# Use a colorblind-safe palette and distinct line styles\n",
    "# From Paul Tol's color schemes: https://personal.sron.nl/~pault/\n",
    "color_localized = \"#0072B2\"  # Blue\n",
    "color_non_localized = \"#D55E00\"  # Orange\n",
    "\n",
    "ax1.plot(\n",
    "    model_grid,\n",
    "    true_parameters,\n",
    "    color=\"black\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    "    label=\"True Parameters\",\n",
    ")\n",
    "ax1.plot(\n",
    "    model_grid,\n",
    "    prior_mean,\n",
    "    color=\"gray\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=1.5,\n",
    "    label=\"Prior Mean\",\n",
    ")\n",
    "ax1.plot(\n",
    "    model_grid,\n",
    "    posterior_mean,\n",
    "    color=color_localized,\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2.5,\n",
    "    label=\"Localized Posterior Mean\",\n",
    ")\n",
    "ax1.plot(\n",
    "    model_grid,\n",
    "    posterior_mean_ESMDA,\n",
    "    color=color_non_localized,\n",
    "    linestyle=\"-.\",\n",
    "    linewidth=2.5,\n",
    "    label=\"Non-Localized Posterior Mean\",\n",
    ")\n",
    "ax1.axvline(\n",
    "    j_obs,\n",
    "    color=\"black\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=1.5,\n",
    "    label=f\"Observation Location (x={j_obs})\",\n",
    ")\n",
    "\n",
    "ax1.set_ylabel(\"Parameter Value\")\n",
    "ax1.set_title(\"Effect of Localized vs. Non-Localized Data Assimilation\")\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot 2: Localization weights\n",
    "ax2.plot(model_grid, rho, color=\"black\", label=\"Localization Weight (rho)\")\n",
    "ax2.set_xlabel(\"Model Parameter Index (Grid Point)\")\n",
    "ax2.set_ylabel(\"Weight\")\n",
    "ax2.set_title(\"Localization Function\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# What to expect:\n",
    "# The prior mean should be a noisy line centered around 0.\n",
    "#\n",
    "# The Localized Posterior Mean should be pulled from approx. 0 towards the\n",
    "# observation value of 1.0. This update should be strong at the observation location\n",
    "# and decay smoothly to zero away from it, following the shape of the localization function.\n",
    "#\n",
    "# The Non-Localized Posterior Mean will show updates across the ENTIRE\n",
    "# domain, not just near the observation.\n",
    "# This is because a small ensemble size creates spurious\n",
    "# correlations between the observation and distant, unrelated parameters.\n",
    "#\n",
    "# Consequently, the non-localized update will look noisy and physically unrealistic across the\n",
    "# domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a67b0-67d9-4ab0-a650-cda668946475",
   "metadata": {},
   "source": [
    "# 2D Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df4568-f563-4f3d-8e6e-a43ddd096289",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx, Ny = 10, 10\n",
    "N_m = Nx * Ny\n",
    "N_e = 50\n",
    "x_obs, y_obs = 5, 5\n",
    "\n",
    "seed = 42\n",
    "\n",
    "alpha_i = 1\n",
    "obs_error_var = 0.01\n",
    "\n",
    "true_parameters = np.zeros(N_m)\n",
    "true_observations = np.array([1.0])\n",
    "C_D = np.array([obs_error_var])\n",
    "\n",
    "# Generate Initial Ensemble and Predictions\n",
    "rng = np.random.default_rng(seed)\n",
    "X_prior = rng.normal(loc=0.0, scale=0.5, size=(N_m, N_e))\n",
    "\n",
    "# Convert the 2D observation index to a flat 1D index for slicing\n",
    "flat_obs_index = y_obs * Nx + x_obs\n",
    "Y = X_prior[[flat_obs_index], :]\n",
    "\n",
    "# Construct 2D Localization `rho`\n",
    "localization_radius = 1\n",
    "\n",
    "# Create a 2D coordinate grid\n",
    "xx, yy = np.meshgrid(np.arange(Nx), np.arange(Ny))\n",
    "# Calculate 2D Euclidean distance from every point to the observation\n",
    "distances_2d = np.sqrt((xx - x_obs) ** 2 + (yy - y_obs) ** 2)\n",
    "# Flatten the 2D distance map to a 1D vector to match the parameter vector\n",
    "distances = distances_2d.flatten()\n",
    "\n",
    "rho = np.exp(-0.5 * (distances / localization_radius) ** 2).reshape(-1, 1)\n",
    "\n",
    "# Run Assimilations\n",
    "esmda_distance = DistanceESMDA(\n",
    "    covariance=C_D, observations=true_observations, alpha=alpha_i, seed=rng\n",
    ")\n",
    "X_posterior = esmda_distance.assimilate(X=X_prior, Y=Y, rho=rho)\n",
    "\n",
    "esmda = ESMDA(covariance=C_D, observations=true_observations, alpha=alpha_i, seed=rng)\n",
    "X_posterior_global = esmda.assimilate(X=X_prior, Y=Y)\n",
    "\n",
    "# Reshape Data for Plotting\n",
    "\n",
    "# Reshape the 1D vectors back into 2D grids for visualization\n",
    "prior_mean = np.mean(X_prior, axis=1)\n",
    "prior_mean_2d = prior_mean.reshape((Ny, Nx))\n",
    "posterior_mean = np.mean(X_posterior, axis=1)\n",
    "posterior_mean_2d = posterior_mean.reshape((Ny, Nx))\n",
    "\n",
    "posterior_mean_global = np.mean(X_posterior_global, axis=1)\n",
    "posterior_mean_global_2d = posterior_mean_global.reshape((Ny, Nx))\n",
    "rho_2d = rho.reshape((Ny, Nx))\n",
    "\n",
    "# It's often more insightful to visualize the UPDATE (posterior - prior)\n",
    "update_localized_2d = posterior_mean_2d - prior_mean_2d\n",
    "update_global_2d = posterior_mean_global_2d - prior_mean_2d\n",
    "\n",
    "# --- Create the Plots ---\n",
    "# Use a 2x3 grid to show the most important comparisons\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 10))\n",
    "\n",
    "# Find the min/max across both update fields for a fair comparison\n",
    "update_min = min(update_localized_2d.min(), update_global_2d.min())\n",
    "update_max = max(update_localized_2d.max(), update_global_2d.max())\n",
    "\n",
    "# Localization Function (rho)\n",
    "im = axes[0].imshow(rho_2d, cmap=\"viridis\")\n",
    "axes[0].set_title(\"Localization Function (rho)\")\n",
    "\n",
    "# Localized Update\n",
    "im = axes[1].imshow(\n",
    "    update_localized_2d, cmap=\"coolwarm\", vmin=update_min, vmax=update_max\n",
    ")\n",
    "axes[1].set_title(\"Localized Update\")\n",
    "\n",
    "# Non-Localized Update\n",
    "im = axes[2].imshow(update_global_2d, cmap=\"coolwarm\", vmin=update_min, vmax=update_max)\n",
    "axes[2].set_title(\"Non-Localized Update\")\n",
    "\n",
    "# Mark the observation location on all plots and hide ticks\n",
    "for ax in axes.flat:\n",
    "    ax.plot(x_obs, y_obs, \"r+\", markersize=12, markeredgewidth=2)  # Red cross\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da966e58-c4da-4470-bad0-32dec9b07452",
   "metadata": {},
   "source": [
    "# 3D case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb8b0a-1942-44db-bf9d-f79e9239bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx, Ny, Nz = 92, 146, 66\n",
    "N_m = Nx * Ny * Nz\n",
    "N_e = 100\n",
    "x_obs, y_obs, z_obs = 50, 50, 2\n",
    "\n",
    "seed = 42\n",
    "alpha_i = 1\n",
    "obs_error_var = 0.01\n",
    "\n",
    "true_parameters = np.zeros(N_m)\n",
    "true_observations = np.array([1.0])\n",
    "C_D = np.array([obs_error_var])\n",
    "\n",
    "# Generate Initial Ensemble and Predictions\n",
    "rng = np.random.default_rng(seed)\n",
    "X_prior = rng.normal(loc=0.0, scale=0.5, size=(N_m, N_e))\n",
    "\n",
    "# Convert the 3D observation index to a flat 1D index for slicing\n",
    "flat_obs_index = (z_obs * Nx * Ny) + (y_obs * Nx) + x_obs\n",
    "Y = X_prior[[flat_obs_index], :]\n",
    "\n",
    "# gmour 2025.07.24\n",
    "# Construct 3D Localization `rho`\n",
    "localization_radius_x = 2.0\n",
    "localization_radius_y = 3.0\n",
    "localization_radius_z = 5.0\n",
    "\n",
    "# Create 3D coordinate grids\n",
    "zz, yy, xx = np.meshgrid(np.arange(Nz), np.arange(Ny), np.arange(Nx), indexing=\"ij\")\n",
    "\n",
    "# gmour 2025.07.24\n",
    "# Calculate 3D Euclidean distance from every point to the observation\n",
    "distances_3d = np.sqrt(\n",
    "    ((xx - x_obs) / localization_radius_x) ** 2\n",
    "    + ((yy - y_obs) / localization_radius_y) ** 2\n",
    "    + ((zz - z_obs) / localization_radius_z) ** 2\n",
    ")\n",
    "distances = distances_3d.flatten()\n",
    "\n",
    "rho = np.exp(-0.5 * distances**2).reshape(-1, 1)\n",
    "\n",
    "# Run Assimilations\n",
    "\n",
    "esmda_distance = DistanceESMDA(\n",
    "    covariance=C_D, observations=true_observations, alpha=alpha_i, seed=rng\n",
    ")\n",
    "X_posterior = esmda_distance.assimilate(X=X_prior, Y=Y, rho=rho)\n",
    "\n",
    "esmda = ESMDA(covariance=C_D, observations=true_observations, alpha=alpha_i, seed=rng)\n",
    "X_posterior_global = esmda.assimilate(X=X_prior, Y=Y)\n",
    "\n",
    "# Reshape Data and Prepare for 3D Visualization\n",
    "prior_mean = np.mean(X_prior, axis=1)\n",
    "posterior_mean = np.mean(X_posterior, axis=1)\n",
    "\n",
    "# Reshape the 1D vectors into 3D volumes\n",
    "rho_3d = rho.reshape((Nz, Ny, Nx))\n",
    "update_localized_3d = (posterior_mean - prior_mean).reshape((Nz, Ny, Nx))\n",
    "update_global_3d = (np.mean(X_posterior_global, axis=1) - prior_mean).reshape(\n",
    "    (Nz, Ny, Nx)\n",
    ")\n",
    "\n",
    "# Create 3D Cross-Sectional Plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "fig.suptitle(\"3D Cross-Sectional Views of Localization and Updates\", fontsize=16)\n",
    "\n",
    "# Row 1: Slices of the Localization Function (rho)\n",
    "im_rho = axes[0, 0].imshow(rho_3d[z_obs, :, :], cmap=\"viridis\", vmin=0, vmax=1)\n",
    "axes[0, 0].set_title(f\"Rho - XY Slice at z={z_obs}\")\n",
    "\n",
    "axes[0, 1].imshow(rho_3d[:, y_obs, :], cmap=\"viridis\", vmin=0, vmax=1)\n",
    "axes[0, 1].set_title(f\"Rho - XZ Slice at y={y_obs}\")\n",
    "\n",
    "axes[0, 2].imshow(rho_3d[:, :, x_obs], cmap=\"viridis\", vmin=0, vmax=1)\n",
    "axes[0, 2].set_title(f\"Rho - YZ Slice at x={x_obs}\")\n",
    "\n",
    "fig.colorbar(\n",
    "    im_rho, ax=axes[0, :], location=\"right\", shrink=0.8, label=\"Localization Weight\"\n",
    ")\n",
    "\n",
    "# Slices of the Update Fields\n",
    "# Find a single, symmetric color scale for both update plots\n",
    "update_max_abs = np.max([np.abs(update_localized_3d), np.abs(update_global_3d)])\n",
    "vmin_update, vmax_update = -update_max_abs, update_max_abs\n",
    "\n",
    "# Localized Update\n",
    "im_update = axes[1, 0].imshow(\n",
    "    update_localized_3d[z_obs, :, :],\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=vmin_update,\n",
    "    vmax=vmax_update,\n",
    ")\n",
    "axes[1, 0].set_title(\"Localized Update - XY Slice\")\n",
    "\n",
    "axes[1, 1].imshow(\n",
    "    update_localized_3d[:, y_obs, :],\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=vmin_update,\n",
    "    vmax=vmax_update,\n",
    ")\n",
    "axes[1, 1].set_title(\"Localized Update - XZ Slice\")\n",
    "\n",
    "axes[1, 2].imshow(\n",
    "    update_localized_3d[:, :, x_obs],\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=vmin_update,\n",
    "    vmax=vmax_update,\n",
    ")\n",
    "axes[1, 2].set_title(\"Localized Update - YZ Slice\")\n",
    "\n",
    "# Add Annotations to All Plots\n",
    "# Add crosshairs to pinpoint the observation location in each slice\n",
    "axes[0, 0].axhline(y_obs, color=\"r\", linestyle=\":\", lw=1)\n",
    "axes[0, 0].axvline(x_obs, color=\"r\", linestyle=\":\", lw=1)\n",
    "axes[0, 1].axhline(z_obs, color=\"r\", linestyle=\":\", lw=1)\n",
    "axes[0, 1].axvline(x_obs, color=\"r\", linestyle=\":\", lw=1)\n",
    "axes[0, 2].axhline(z_obs, color=\"r\", linestyle=\":\", lw=1)\n",
    "axes[0, 2].axvline(y_obs, color=\"r\", linestyle=\":\", lw=1)\n",
    "\n",
    "axes[1, 0].axhline(y_obs, color=\"k\", linestyle=\":\", lw=1)\n",
    "axes[1, 0].axvline(x_obs, color=\"k\", linestyle=\":\", lw=1)\n",
    "axes[1, 1].axhline(z_obs, color=\"k\", linestyle=\":\", lw=1)\n",
    "axes[1, 1].axvline(x_obs, color=\"k\", linestyle=\":\", lw=1)\n",
    "axes[1, 2].axhline(z_obs, color=\"k\", linestyle=\":\", lw=1)\n",
    "axes[1, 2].axvline(y_obs, color=\"k\", linestyle=\":\", lw=1)\n",
    "\n",
    "# Hide axis ticks for a cleaner look\n",
    "for ax in axes.flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef00a8e-0921-43ac-8d35-10d6feda8f22",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ed7c6-701a-468b-a5ad-ddf2d032dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def gaspari_cohn_localization(distances, radius):\n",
    "    \"\"\"Gaspari-Cohn localization with compact support at 2*radius\"\"\"\n",
    "    r = distances / radius\n",
    "    rho = np.zeros_like(r)\n",
    "\n",
    "    # Compact support: zero beyond 2*radius\n",
    "    mask1 = r <= 1\n",
    "    mask2 = (r > 1) & (r <= 2)\n",
    "\n",
    "    # Gaspari-Cohn function with smooth derivatives\n",
    "    rho[mask1] = (\n",
    "        1\n",
    "        - (5 / 3) * r[mask1] ** 2\n",
    "        + (5 / 8) * r[mask1] ** 3\n",
    "        + (1 / 2) * r[mask1] ** 4\n",
    "        - (1 / 4) * r[mask1] ** 5\n",
    "    )\n",
    "    rho[mask2] = (\n",
    "        4\n",
    "        - 5 * r[mask2]\n",
    "        + (5 / 3) * r[mask2] ** 2\n",
    "        + (5 / 8) * r[mask2] ** 3\n",
    "        - (1 / 2) * r[mask2] ** 4\n",
    "        + (1 / 12) * r[mask2] ** 5\n",
    "        - 2 / (3 * r[mask2])\n",
    "    )\n",
    "\n",
    "    return rho\n",
    "\n",
    "\n",
    "def create_multi_well_localization(\n",
    "    well_locations, obs_per_well, grid_size, radii_azimuth\n",
    "):\n",
    "    \"\"\"Create localization matrix where all observations at same well share localization\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    well_locations : array_like\n",
    "        Indices of well locations\n",
    "    obs_per_well : int\n",
    "        Number of observations per well\n",
    "    grid_size : int\n",
    "        Size of square grid (grid_size x grid_size)\n",
    "    radius : float\n",
    "        Localization radius (function has compact support at 2*radius)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    rho : ndarray\n",
    "        Localization matrix of shape (n_params, n_obs)\n",
    "    \"\"\"\n",
    "\n",
    "    n_wells = len(well_locations)\n",
    "    n_obs = n_wells * obs_per_well\n",
    "    n_params = grid_size * grid_size\n",
    "\n",
    "    # Create coordinate grids\n",
    "    xx, yy = np.meshgrid(np.arange(grid_size), np.arange(grid_size))\n",
    "\n",
    "    xx_flat = xx.flatten()\n",
    "    yy_flat = yy.flatten()\n",
    "\n",
    "    rho = np.zeros((n_params, n_obs))\n",
    "\n",
    "    for current_index, well_idx in enumerate(well_locations):\n",
    "        # Convert 1D grid index to 2D coordinates\n",
    "        # For a flattened grid: index = y * grid_size + x\n",
    "        # So: x = index % grid_size, y = index // grid_size\n",
    "        well_x = well_idx % grid_size\n",
    "        well_y = well_idx // grid_size\n",
    "\n",
    "        # Perform a simple 2D rotation. Equations available in:\n",
    "        # Emerick, A., & Reynolds, A. (2011). Combining sensitivities and prior information for covariance localization\n",
    "        # in the ensemble Kalman filter for petroleum reservoir applications. Computational Geosciences, 15(2), 251-269.\n",
    "        # Equations #18 and #19\n",
    "\n",
    "        rotated_x_dist = (xx_flat - well_x) * np.cos(radii_azimuth[2] * np.pi / 180) + (\n",
    "            yy_flat - well_y\n",
    "        ) * np.sin(radii_azimuth[2] * np.pi / 180)\n",
    "        rotated_y_dist = -(xx_flat - well_x) * np.sin(\n",
    "            radii_azimuth[2] * np.pi / 180\n",
    "        ) + (yy_flat - well_y) * np.cos(radii_azimuth[2] * np.pi / 180)\n",
    "\n",
    "        distances = np.sqrt(\n",
    "            (rotated_x_dist / radii_azimuth[0]) ** 2\n",
    "            + (rotated_y_dist / radii_azimuth[1]) ** 2\n",
    "        )\n",
    "\n",
    "        rho_well = gaspari_cohn_localization(distances, 1)\n",
    "\n",
    "        # Populate rho by replicating rho_well obs_per_well times:\n",
    "        rho[:, current_index * obs_per_well : (current_index + 1) * obs_per_well] = (\n",
    "            np.tile(rho_well.reshape(-1, 1), (1, obs_per_well))\n",
    "        )\n",
    "\n",
    "    return rho\n",
    "\n",
    "\n",
    "def visualize_localization_effect(\n",
    "    X_prior, X_posterior, well_locations, rho, grid_size, case_name=\"\"\n",
    "):\n",
    "    \"\"\"Visualize the localization function and its effect on the update\"\"\"\n",
    "\n",
    "    # Calculate ensemble means\n",
    "    prior_mean = np.mean(X_prior, axis=1)\n",
    "    posterior_mean = np.mean(X_posterior, axis=1)\n",
    "\n",
    "    # Reshape to 2D grids\n",
    "    prior_mean_2d = prior_mean.reshape((grid_size, grid_size))\n",
    "    posterior_mean_2d = posterior_mean.reshape((grid_size, grid_size))\n",
    "    rho_2d = rho[:, 0].reshape(\n",
    "        (grid_size, grid_size)\n",
    "    )  # Use first column since all are the same\n",
    "\n",
    "    # Calculate update\n",
    "    update_2d = posterior_mean_2d - prior_mean_2d\n",
    "\n",
    "    # Convert well locations to 2D coordinates\n",
    "    well_coords = [(idx % grid_size, idx // grid_size) for idx in well_locations]\n",
    "\n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Plot 1: Localization function\n",
    "    im1 = axes[0].imshow(rho_2d, cmap=\"viridis\", origin=\"lower\")\n",
    "    axes[0].set_title(\"Localization Function (rho)\")\n",
    "    axes[0].set_xlabel(\"X coordinate\")\n",
    "    axes[0].set_ylabel(\"Y coordinate\")\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "    # Mark well locations\n",
    "    for well_x, well_y in well_coords:\n",
    "        axes[0].plot(well_x, well_y, \"r+\", markersize=15, markeredgewidth=3)\n",
    "\n",
    "    # Plot 2: Localized update\n",
    "    update_max = max(abs(update_2d.min()), abs(update_2d.max()))\n",
    "    im2 = axes[1].imshow(\n",
    "        update_2d, cmap=\"RdBu_r\", origin=\"lower\", vmin=-update_max, vmax=update_max\n",
    "    )\n",
    "    axes[1].set_title(\"Localized Update\")\n",
    "    axes[1].set_xlabel(\"X coordinate\")\n",
    "    axes[1].set_ylabel(\"Y coordinate\")\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "    # Mark well locations\n",
    "    for well_x, well_y in well_coords:\n",
    "        axes[1].plot(well_x, well_y, \"k+\", markersize=15, markeredgewidth=3)\n",
    "\n",
    "    plt.suptitle(f\"Localization Effect {case_name}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print some statistics\n",
    "    print(\"    Localization statistics:\")\n",
    "    print(\n",
    "        f\"      Sparsity: {np.mean(rho_2d == 0) * 100:.1f}% of parameters have zero localization\"\n",
    "    )\n",
    "    print(f\"      Max localization: {rho_2d.max():.3f}\")\n",
    "    print(f\"      Update range: [{update_2d.min():.4f}, {update_2d.max():.4f}]\")\n",
    "    print(f\"      Update std: {update_2d.std():.4f}\")\n",
    "    print(f\"      Rho shape: {rho.shape}\")\n",
    "\n",
    "\n",
    "def visualize_localization_effect_interactive(\n",
    "    X_prior, X_posterior, well_locations, rho, grid_size, case_name=\"\"\n",
    "):\n",
    "    \"\"\"Interactive visualization of the localization function and its effect on the update\"\"\"\n",
    "\n",
    "    # Calculate ensemble means\n",
    "    prior_mean = np.mean(X_prior, axis=1)\n",
    "    posterior_mean = np.mean(X_posterior, axis=1)\n",
    "\n",
    "    # Reshape to 2D grids\n",
    "    prior_mean_2d = prior_mean.reshape((grid_size, grid_size))\n",
    "    posterior_mean_2d = posterior_mean.reshape((grid_size, grid_size))\n",
    "\n",
    "    # Calculate update\n",
    "    update_2d = posterior_mean_2d - prior_mean_2d\n",
    "\n",
    "    # Convert well locations to 2D coordinates\n",
    "    well_coords = [(idx % grid_size, idx // grid_size) for idx in well_locations]\n",
    "\n",
    "    def plot_slice(slice_index):\n",
    "        rho_2d = rho[:, slice_index].reshape((grid_size, grid_size))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "        # Plot 1: Localization function\n",
    "        im1 = axes[0].imshow(rho_2d, cmap=\"viridis\", origin=\"lower\")\n",
    "        axes[0].set_title(f\"Localization Function (rho[:, {slice_index}])\")\n",
    "        axes[0].set_xlabel(\"X coordinate\")\n",
    "        axes[0].set_ylabel(\"Y coordinate\")\n",
    "        plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "        for well_x, well_y in well_coords:\n",
    "            axes[0].plot(well_x, well_y, \"r+\", markersize=15, markeredgewidth=3)\n",
    "\n",
    "        # Plot 2: Localized update\n",
    "        update_max = max(abs(update_2d.min()), abs(update_2d.max()))\n",
    "        im2 = axes[1].imshow(\n",
    "            update_2d, cmap=\"RdBu_r\", origin=\"lower\", vmin=-update_max, vmax=update_max\n",
    "        )\n",
    "        axes[1].set_title(\"Localized Update\")\n",
    "        axes[1].set_xlabel(\"X coordinate\")\n",
    "        axes[1].set_ylabel(\"Y coordinate\")\n",
    "        plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "        for well_x, well_y in well_coords:\n",
    "            axes[1].plot(well_x, well_y, \"k+\", markersize=15, markeredgewidth=3)\n",
    "\n",
    "        plt.suptitle(f\"Localization Effect {case_name}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Print statistics\n",
    "        print(f\"    Localization statistics for slice {slice_index}:\")\n",
    "        print(\n",
    "            f\"      Sparsity: {np.mean(rho_2d == 0) * 100:.1f}% of parameters have zero localization\"\n",
    "        )\n",
    "        print(f\"      Max localization: {rho_2d.max():.3f}\")\n",
    "        print(f\"      Update range: [{update_2d.min():.4f}, {update_2d.max():.4f}]\")\n",
    "        print(f\"      Update std: {update_2d.std():.4f}\")\n",
    "        print(f\"      Rho shape: {rho.shape}\")\n",
    "\n",
    "    # Create interactive slider\n",
    "    interact(\n",
    "        plot_slice, slice_index=IntSlider(min=0, max=rho.shape[1] - 1, step=1, value=0)\n",
    "    )\n",
    "\n",
    "\n",
    "def time_large_scale_performance():\n",
    "    \"\"\"Test performance on large-scale problems\"\"\"\n",
    "\n",
    "    # Test cases: (n_params, n_wells, obs_per_well)\n",
    "    test_cases = [\n",
    "        (200 * 200, 100, 1),\n",
    "        # (115*115, 115*115, 1),\n",
    "        # (418*418, 115*115, 1),\n",
    "        # (660*660, 115*115, 1),\n",
    "        # (933 * 933, 60 * 60, 1),\n",
    "        # (100*100, 5, 1000),\n",
    "        # (1000*1000, 50, 20),\n",
    "        # (1000*1000, 100, 10),\n",
    "    ]\n",
    "\n",
    "    n_ensemble = 100\n",
    "    n_trials = 1  # Might want to reduce this for very large problems\n",
    "    # main, normal, azimuth\n",
    "    localization_radii_azimuth = [50, 30, 45]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    print(\"Testing large-scale performance...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for i, (n_params, n_wells, obs_per_well) in enumerate(test_cases):\n",
    "        n_obs = n_wells * obs_per_well\n",
    "        print(\n",
    "            f\"\\nTest Case {i + 1}: N_params={n_params:,}, N_wells={n_wells}, Obs_per_well={obs_per_well}, Total_obs={n_obs}\"\n",
    "        )\n",
    "\n",
    "        grid_size = int(np.sqrt(n_params))\n",
    "        print(\n",
    "            f\"Grid: {grid_size}x{grid_size}, Wells: {n_wells}, Obs/well: {obs_per_well}\"\n",
    "        )\n",
    "\n",
    "        # Verify it's a perfect square\n",
    "        assert grid_size * grid_size == n_params, f\"Not a perfect square: {n_params}\"\n",
    "\n",
    "        trial_times = []\n",
    "\n",
    "        for trial in range(n_trials):\n",
    "            print(f\"  Trial {trial + 1}/{n_trials}...\")\n",
    "\n",
    "            # Setup\n",
    "            # rng = np.random.default_rng(42 + trial)\n",
    "            rng = np.random.default_rng()\n",
    "\n",
    "            # Generate ensemble\n",
    "            print(\"    Generating ensemble...\")\n",
    "            X_prior = rng.normal(0, 0.5, size=(n_params, n_ensemble))\n",
    "\n",
    "            # Generate well locations and observations\n",
    "            print(\"    Selecting well locations and observations...\")\n",
    "\n",
    "            # First, select well locations (unique spatial positions)\n",
    "            well_locations = rng.choice(n_params, size=n_wells, replace=False)\n",
    "\n",
    "            # Then, create multiple observations per well\n",
    "            # For simplicity, all observations at a well have the same location\n",
    "            # In reality, they might be slightly offset or represent different variables\n",
    "            obs_indices = []\n",
    "            for well_loc in well_locations:\n",
    "                for _ in range(obs_per_well):\n",
    "                    obs_indices.append(well_loc)\n",
    "\n",
    "            # Generate observations by sampling the forward model at well locations\n",
    "            # Note: obs_indices can be longer than n_params since we replicate well locations\n",
    "            # for multiple observations per well. NumPy allows repeated indices, so\n",
    "            # X_prior[obs_indices, :] creates multiple copies of the same model values.\n",
    "            obs_indices = np.array(obs_indices)\n",
    "            # Using identity model Y = g(X) = X\n",
    "            Y = X_prior[obs_indices, :]\n",
    "\n",
    "            # Start timing the critical section\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            print(\"    Creating localization matrix...\")\n",
    "\n",
    "            # Create localization matrix based on well locations\n",
    "            # All observations at same well share same localization\n",
    "            rho = create_multi_well_localization(\n",
    "                well_locations, obs_per_well, grid_size, localization_radii_azimuth\n",
    "            )\n",
    "\n",
    "            print(\"    Running assimilation...\")\n",
    "\n",
    "            # Run assimilation with all observations\n",
    "            esmda = DistanceESMDA(\n",
    "                covariance=np.eye(n_obs) * 0.01,\n",
    "                observations=np.ones(n_obs),\n",
    "                alpha=1,\n",
    "                seed=rng,\n",
    "            )\n",
    "\n",
    "            X_posterior = esmda.assimilate(X=X_prior, Y=Y, rho=rho)\n",
    "\n",
    "            end_time = time.perf_counter()\n",
    "\n",
    "            total_time = end_time - start_time\n",
    "            trial_times.append(total_time)\n",
    "\n",
    "            print(f\"    Time: {total_time:.2f}s\")\n",
    "\n",
    "            # Visualize the localization effect\n",
    "            print(\"    Creating visualization...\")\n",
    "            visualize_localization_effect_interactive(\n",
    "                X_prior,\n",
    "                X_posterior,\n",
    "                well_locations,\n",
    "                rho,\n",
    "                grid_size,\n",
    "                case_name=f\"(Case {i + 1}: {n_wells} wells, {obs_per_well} obs/well, radii and azimuth={localization_radii_azimuth})\",\n",
    "            )\n",
    "\n",
    "            # Clean up large arrays to free memory\n",
    "            del X_prior, X_posterior, Y, rho\n",
    "\n",
    "        avg_time = np.mean(trial_times)\n",
    "        std_time = np.std(trial_times)\n",
    "\n",
    "        result = {\n",
    "            \"n_params\": n_params,\n",
    "            \"n_wells\": n_wells,\n",
    "            \"obs_per_well\": obs_per_well,\n",
    "            \"n_obs\": n_obs,\n",
    "            \"avg_time\": avg_time,\n",
    "            \"std_time\": std_time,\n",
    "            \"trial_times\": trial_times,\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "        print(f\"  Average time: {avg_time:.2f} ± {std_time:.2f}s\")\n",
    "        print(f\"  Time per parameter: {avg_time / n_params * 1e6:.2f} μs/param\")\n",
    "        print(f\"  Time per well: {avg_time / n_wells * 1e3:.2f} ms/well\")\n",
    "        print(f\"  Time per observation: {avg_time / n_obs * 1e3:.2f} ms/obs\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_large_scale_results(results):\n",
    "    \"\"\"Analyze and visualize large-scale results\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"LARGE-SCALE PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        print(\n",
    "            f\"\\nCase {i + 1}: {result['n_params']:,} params, {result['n_wells']} wells, {result['obs_per_well']} obs/well\"\n",
    "        )\n",
    "        print(f\"  Total obs: {result['n_obs']}\")\n",
    "        print(\n",
    "            f\"  Total time: {result['avg_time']:.2f} ± {result['std_time']:.2f} seconds\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  Throughput: {result['n_params'] / result['avg_time']:.0f} params/second\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  Time per param: {result['avg_time'] / result['n_params'] * 1e6:.2f} μs\"\n",
    "        )\n",
    "        print(f\"  Time per well: {result['avg_time'] / result['n_wells'] * 1e3:.2f} ms\")\n",
    "        print(f\"  Time per obs: {result['avg_time'] / result['n_obs'] * 1e3:.2f} ms\")\n",
    "\n",
    "\n",
    "# Performance monitoring decorator (simplified)\n",
    "def monitor_performance(func):\n",
    "    \"\"\"Decorator to monitor time only\"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        print(f\"Function {func.__name__}:\")\n",
    "        print(f\"  Total time: {end_time - start_time:.2f}s\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "time_large_scale_performance = monitor_performance(time_large_scale_performance)\n",
    "\n",
    "results = time_large_scale_performance()\n",
    "analyze_large_scale_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710fad99",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# Extended 3D case for multiple purpose testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c979e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import gaussianfft as sim\n",
    "\n",
    "\n",
    "# This test uses a forward model that is an aritmetic average\n",
    "# of the field parameters into a coarse scale grid\n",
    "def simulate_realizations(\n",
    "    nreal: int,\n",
    "    variogram,\n",
    "    nx: int,\n",
    "    ny: int,\n",
    "    nz: int,\n",
    "    xinc: float,\n",
    "    yinc: float,\n",
    "    zinc: float,\n",
    "    start_seed: int = 123456789,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw realizations of the 3D gaussian fields using specified variogram\n",
    "    Output has dimension (nparam, nreal) where nparam = nx*ny*nz\n",
    "    The flatten parameter vector is 'F'-ordered where (i,j,k)\n",
    "    corresponds to index = i + j*nx + k*nx*ny\n",
    "    \"\"\"\n",
    "    sim.seed(start_seed)\n",
    "    fields = np.zeros((nx * ny * nz, nreal), dtype=np.float32)\n",
    "    for n in range(nreal):\n",
    "        if n % 10 == 0:\n",
    "            print(f\"Simulate realization: {n}\")\n",
    "        # Order is 'F' as output here\n",
    "        field_real_flatten = sim.simulate(variogram, nx, xinc, ny, yinc, nz, zinc)\n",
    "        fields[:, n] = field_real_flatten\n",
    "    return fields\n",
    "\n",
    "\n",
    "def forward_model_real(\n",
    "    field3D: np.ndarray, nx: int, ny: int, nz: int, kx: int, ky: int, kz: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simple linear forward model defined by arithmetic average of field\n",
    "    values within each coarse grid cell.\n",
    "    Calculate average of coarse grid blocks of size (mx,my,mz).\n",
    "    nx = mx*kx,   ny = my *ky , nz = mz * kz\n",
    "    where (kx, ky,kz) is grid size of upscaled grid.\n",
    "\n",
    "    \"\"\"\n",
    "    mx = int(nx / kx)\n",
    "    my = int(ny / ky)\n",
    "    mz = int(nz / kz)\n",
    "    upscaled = np.zeros((kx, ky, kz), order=\"F\", dtype=np.float32)\n",
    "    for kk in range(kz):\n",
    "        zstart = kk * mz\n",
    "        zend = zstart + mz\n",
    "        for jj in range(ky):\n",
    "            ystart = jj * my\n",
    "            yend = ystart + my\n",
    "            for ii in range(kx):\n",
    "                xstart = ii * mx\n",
    "                xend = xstart + mx\n",
    "                selected = field3D[xstart:xend, ystart:yend, zstart:zend]\n",
    "                avg = np.mean(selected)\n",
    "                upscaled[ii, jj, kk] = avg\n",
    "    return upscaled\n",
    "\n",
    "\n",
    "def forward_model(\n",
    "    fields: np.ndarray, nreal: int, nx: int, ny: int, nz: int, kx: int, ky: int, kz: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply the forward model to all realizations.\n",
    "    The response per realization (the upscaled values)\n",
    "    are saved in flatten array. Keep same index order ('F')\n",
    "    for coarse grid values as for the input field.\n",
    "    \"\"\"\n",
    "    upscaled_fields = np.zeros((kx * ky * kz, nreal), dtype=np.float32)\n",
    "    for n in range(nreal):\n",
    "        field = fields[:, n]\n",
    "        field3D = field.reshape((nx, ny, nz), order=\"F\")\n",
    "        upscaled3D = forward_model_real(field3D, nx, ny, nz, kx, ky, kz)\n",
    "        upscaled_fields[:, n] = upscaled3D.flatten(order=\"F\")\n",
    "    return upscaled_fields\n",
    "\n",
    "\n",
    "def gaussian_decay(D):\n",
    "    return np.exp(-3 * D * D)\n",
    "\n",
    "\n",
    "def exponential_decay(D):\n",
    "    return np.exp(-3 * D)\n",
    "\n",
    "\n",
    "def field_parameter_grid_cell_center_xy_coordinates(\n",
    "    xorigo: float,\n",
    "    yorigo: float,\n",
    "    xinc: float,\n",
    "    yinc: float,\n",
    "    rotation: float,\n",
    "    nx: int,\n",
    "    ny: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate global x and y coordinates grid cell center points\n",
    "    of field parameter grid as mesh.\n",
    "    Input:\n",
    "    Field parameter grid has a global rotation point, typically\n",
    "    this is lower left corner point if the grid is unrotated.\n",
    "    Rotation is anticlockwise in degrees. Only the lateral position of\n",
    "    the grid cell center points are of interest for distance based\n",
    "    localization.\n",
    "    Output:\n",
    "    Numpy mesh for x and y location of cell center points in global coordinates\n",
    "    \"\"\"\n",
    "    x_local = np.arange(0.5 * xinc, xinc * (nx + 0.49), xinc, dtype=np.float32)\n",
    "    y_local = np.arange(0.5 * yinc, yinc * (ny + 0.49), yinc, dtype=np.float32)\n",
    "\n",
    "    cosangle = math.cos(rotation * np.pi / 180.0)\n",
    "    sinangle = math.sin(rotation * np.pi / 180.0)\n",
    "\n",
    "    # (x,y) in local coordinate system following simulation box\n",
    "    yy, xx = np.meshgrid(y_local, x_local, indexing=\"ij\")\n",
    "\n",
    "    # Transform to global coordinate system\n",
    "    x_global = xx * cosangle - yy * sinangle + xorigo\n",
    "    y_global = xx * sinangle + yy * cosangle + yorigo\n",
    "    return x_global, y_global\n",
    "\n",
    "\n",
    "def calculate_scaling_factor_for_one_layer(\n",
    "    obs_xpos: float,\n",
    "    obs_ypos: float,\n",
    "    grid_x_coord: np.ndarray,\n",
    "    grid_y_coord: np.ndarray,\n",
    "    main_range: float,\n",
    "    perp_range: float,\n",
    "    ellipse_rotation: float,\n",
    "    scaling_function,\n",
    "    cutoff_value: float = 0.001,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate scaling factors for all pairs of field parameters\n",
    "    and one observation point of a layer in a 3D field\n",
    "    parameter grid (box grid).\n",
    "    Input:\n",
    "    numpy mesh for x and y coordinates of cell centers of field\n",
    "    parameter grid position. Position of observation must be\n",
    "    in the same coordinates. Localization parameters for distance\n",
    "    and rotation of elliptic influence area.\n",
    "    Rotation of ellipse is relative to the coordinate system used.\n",
    "    If used coordinate system is local (simulation box grid),\n",
    "    the rotation angle is relative to the local coordinate x-axis.\n",
    "    If coordinate system is global (e.g.UTM), the rotation\n",
    "    angle is relative to the west-east x-axis.\n",
    "    Output:\n",
    "    scaling factors for all field parameters for one grid layer of\n",
    "    field parameters around observation point given.\n",
    "    \"\"\"\n",
    "    dX = grid_x_coord - obs_xpos\n",
    "    dY = grid_y_coord - obs_ypos\n",
    "    rotation = ellipse_rotation * np.pi / 180.0\n",
    "    cosangle = math.cos(rotation)\n",
    "    sinangle = math.sin(rotation)\n",
    "    #    print(f\"shape of dX: {dX.shape} \")\n",
    "    #    print(f\"shape of dY: {dY.shape} \")\n",
    "    dX_ellipse = (dX * cosangle + dY * sinangle) / main_range\n",
    "    dY_ellipse = (-dX * sinangle + dY * cosangle) / perp_range\n",
    "    distances_2d = np.sqrt(dX_ellipse * dX_ellipse + dY_ellipse * dY_ellipse)\n",
    "    distances = distances_2d.flatten()\n",
    "    scaling_factors = scaling_function(distances)\n",
    "\n",
    "    # Apply cutoff\n",
    "    scaling_factors[scaling_factors < cutoff_value] = 0.0\n",
    "    #    print(f\"Shape of scaling_factor: {scaling_factor_all.shape} \")\n",
    "    return scaling_factors\n",
    "\n",
    "\n",
    "def calculate_rho_for_2d_obs_field(\n",
    "    grid_xlength: float,\n",
    "    grid_ylength: float,\n",
    "    param_grid_nx: int,\n",
    "    param_grid_ny: int,\n",
    "    obs_grid_nx: int,\n",
    "    obs_grid_ny: int,\n",
    "    local_main_range: int,\n",
    "    local_perp_range: int,\n",
    "    local_rotation: float,\n",
    "    tapering_function_name: str,\n",
    "    cutoff_value: float = 0.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate localization scaling factor pairs of field parameters and observations.\n",
    "    Input:\n",
    "    The field parameter is specified on a box grid with origo in global coordinates\n",
    "    and grid orientation relative to global coordinates (e.g UTM). Rotation angle is\n",
    "    positive anti-clockwise and in degrees.\n",
    "    The size of the rectangular box is specified.\n",
    "    The observations are assumed to be located on a 2D grid oriented and located and\n",
    "    with position as the field parameter grid and with same size.\n",
    "    The grid resolution (increments) of the 2D grid with observations can be different\n",
    "    from the field parameter grid.\n",
    "    The specified localization ranges define the influence range of the localization and\n",
    "    are parameters used by the specified localization function.\n",
    "    Output:\n",
    "    Update the matrix rho corresponding to one layer of the 3D field parameter grid\n",
    "    with scaling factors for each pair of field parameters and observations.\n",
    "    \"\"\"\n",
    "\n",
    "    # def calculate_scaling_factor_for_one_layer(\n",
    "    # obs_xpos:float, obs_ypos:float,\n",
    "    # grid_x_coord:np.ndarray, grid_y_coord:np.ndarray,\n",
    "    # main_range:float, perp_range:float, ellipse_rotation:float, cutoff_value:float,\n",
    "    # scaling_function\n",
    "    nparam_one_layer = param_grid_nx * param_grid_ny\n",
    "    nobs = obs_grid_nx * obs_grid_ny\n",
    "    if param_grid_nx == obs_grid_nx and param_grid_ny == obs_grid_ny:\n",
    "        if local_main_range == 0.0 or local_perp_range == 0.0:\n",
    "            # localization with 0 influence range means that only the observation\n",
    "            # located in same position as the field parameter contributes to the\n",
    "            # update of the field parameter.\n",
    "            # (Co-located field parameter and observation)\n",
    "            print(\n",
    "                \"Field parameters (x,y) position and (i,j) indices are co-located with\"\n",
    "                \"the observation field\"\n",
    "            )\n",
    "            rho_for_one_layer = np.identity(nparam_one_layer, dtype=np.float32)\n",
    "            return rho_for_one_layer\n",
    "    # TODO:  Can maybe speed up this\n",
    "    xinc = grid_xlength / param_grid_nx\n",
    "    yinc = grid_ylength / param_grid_ny\n",
    "    xinc_obs = grid_xlength / obs_grid_nx\n",
    "    yinc_obs = grid_ylength / obs_grid_ny\n",
    "\n",
    "    x_local = np.arange(param_grid_nx)\n",
    "    x_local = (x_local + 0.5) * xinc\n",
    "    y_local = np.arange(param_grid_ny)\n",
    "    y_local = (y_local + 0.5) * yinc\n",
    "    grid_y_coord, grid_x_coord = np.meshgrid(y_local, x_local, indexing=\"ij\")\n",
    "\n",
    "    if tapering_function_name == \"exponential\":\n",
    "        scaling_function = exponential_decay\n",
    "    elif tapering_function_name == \"gaussian\":\n",
    "        scaling_function = gaussian_decay\n",
    "\n",
    "    # Position relative to the local coordinate system (simbox coordinate system)\n",
    "    rho_for_one_layer = np.zeros((nparam_one_layer, nobs))\n",
    "    for j in range(obs_grid_ny):\n",
    "        y_pos_obs = (j + 0.5) * yinc_obs\n",
    "        for i in range(obs_grid_nx):\n",
    "            obs_nr = i + j * obs_grid_nx\n",
    "            x_pos_obs = (i + 0.5) * xinc_obs\n",
    "            rho_for_one_layer[:, obs_nr] = calculate_scaling_factor_for_one_layer(\n",
    "                x_pos_obs,\n",
    "                y_pos_obs,\n",
    "                grid_x_coord,\n",
    "                grid_y_coord,\n",
    "                local_main_range,\n",
    "                local_perp_range,\n",
    "                local_rotation,\n",
    "                scaling_function,\n",
    "                cutoff_value=cutoff_value,\n",
    "            )\n",
    "\n",
    "    return rho_for_one_layer\n",
    "\n",
    "\n",
    "def calculate_rho_for_2d_obs_field_version2(\n",
    "    grid_xlength: float,\n",
    "    grid_ylength: float,\n",
    "    param_grid_nx: int,\n",
    "    param_grid_ny: int,\n",
    "    obs_grid_nx: int,\n",
    "    obs_grid_ny: int,\n",
    "    local_main_range: int,\n",
    "    local_perp_range: int,\n",
    "    local_rotation: float,\n",
    "    tapering_function_name: str,\n",
    "    cutoff_value: float = 0.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate localization scaling factor pairs of field parameters and observations.\n",
    "    Input:\n",
    "    The field parameter is specified on a box grid with origo in global coordinates\n",
    "    and grid orientation relative to global coordinates (e.g UTM). Rotation angle is\n",
    "    positive anti-clockwise and in degrees.\n",
    "    The size of the rectangular box is specified.\n",
    "    The observations are assumed to be located on a 2D grid oriented and located and\n",
    "    with position as the field parameter grid and with same size.\n",
    "    The grid resolution (increments) of the 2D grid with observations can be different\n",
    "    from the field parameter grid.\n",
    "    The specified localization ranges define the influence range of the localization and\n",
    "    are parameters used by the specified localization function.\n",
    "    Output:\n",
    "    Update the matrix rho corresponding to one layer of the 3D field parameter grid\n",
    "    with scaling factors for each pair of field parameters and observations.\n",
    "    \"\"\"\n",
    "\n",
    "    def scaling_function_gaussian(distance: float):\n",
    "        return math.exp(-3.0 * distance * distance)\n",
    "\n",
    "    def scaling_function_exponential(distance: float):\n",
    "        return math.exp(-3.0 * distance)\n",
    "\n",
    "    nparam_one_layer = param_grid_nx * param_grid_ny\n",
    "    nobs = obs_grid_nx * obs_grid_ny\n",
    "    if param_grid_nx == obs_grid_nx and param_grid_ny == obs_grid_ny:\n",
    "        if local_main_range == 0.0 or local_perp_range == 0.0:\n",
    "            # localization with 0 influence range means that only the observation\n",
    "            # located in same position as the field parameter contributes to the\n",
    "            # update of the field parameter.\n",
    "            # (Co-located field parameter and observation)\n",
    "            print(\n",
    "                \"Field parameters (x,y) position and (i,j) indices are co-located with\"\n",
    "                \"the observation field\"\n",
    "            )\n",
    "            rho_for_one_layer = np.identity(nparam_one_layer, dtype=np.float32)\n",
    "            return rho_for_one_layer\n",
    "\n",
    "    rho_for_one_layer = np.zeros((nparam_one_layer, nobs))\n",
    "    selected_param_2d = np.zeros((param_grid_nx, param_grid_ny), dtype=bool)\n",
    "    if tapering_function_name == \"gaussian\":\n",
    "        scaling_function = scaling_function_gaussian\n",
    "    elif tapering_function_name == \"exponential\":\n",
    "        scaling_function = scaling_function_exponential\n",
    "    xinc = grid_xlength / param_grid_nx\n",
    "    yinc = grid_ylength / param_grid_ny\n",
    "    xinc_obs = grid_xlength / obs_grid_nx\n",
    "    yinc_obs = grid_ylength / obs_grid_ny\n",
    "\n",
    "    # localization range in number of field parameter grid cell increments\n",
    "    used_number_of_ranges = 1.2\n",
    "    irange = int((used_number_of_ranges * local_main_range / xinc) + 0.5)\n",
    "    jrange = int((used_number_of_ranges * local_perp_range / yinc) + 0.5)\n",
    "\n",
    "    obs_grid_xpos = np.arange(0.5 * xinc_obs, grid_xlength, xinc_obs)\n",
    "    obs_grid_ypos = np.arange(0.5 * yinc_obs, grid_ylength, yinc_obs)\n",
    "    print(f\"len(obs_grid_xpos):  {len(obs_grid_xpos)}  obs_grid_nx= {obs_grid_nx})\")\n",
    "    print(f\"len(obs_grid_ypos):  {len(obs_grid_ypos)}  obs_grid_ny= {obs_grid_ny})\")\n",
    "    # Calculate a template for scaling factors for localization for a neighbourhood\n",
    "    # around one arbitrary position (Only distance is relevant here)\n",
    "    # Choose position (0,0)\n",
    "    a = xinc / local_main_range\n",
    "    b = yinc / local_perp_range\n",
    "    scaling_factor_template = np.zeros(\n",
    "        (2 * irange + 1, 2 * jrange + 1), dtype=np.float32\n",
    "    )\n",
    "    for j in range(-jrange, jrange + 1):\n",
    "        dy = (0 - j) * b\n",
    "        for i in range(-irange, irange + 1):\n",
    "            dx = (0 - i) * a\n",
    "            distance_normalized = math.sqrt(dx * dx + dy * dy)\n",
    "            # Shift indices to start at 0\n",
    "            xindx = i + irange\n",
    "            yindx = j + jrange\n",
    "            scaling_factor_template[xindx, yindx] = scaling_function(\n",
    "                distance_normalized\n",
    "            )\n",
    "            # print(f\"(delta_i,delta_j) = ({i},{j}  scaling= {scaling_factor_template[xindx, yindx]})\")\n",
    "\n",
    "    for j in range(obs_grid_ny):\n",
    "        ypos_obs = obs_grid_ypos[j]\n",
    "        J = int(ypos_obs / yinc)\n",
    "        jmin = max(J - jrange, 0)\n",
    "        jmax = min(J + jrange + 1, param_grid_ny)\n",
    "        jmin_selected = max(-jrange, jmin - J) + jrange\n",
    "        jmax_selected = min(jrange + 1, jmax - J) + jrange\n",
    "        # print(f\"j= {j} obs position y: {ypos_obs}  field position y: {(J+0.5) * xinc}  Difference:  {(J+0.5) * xinc -ypos_obs}\")\n",
    "        for i in range(obs_grid_nx):\n",
    "            xpos_obs = obs_grid_xpos[i]\n",
    "            I = int(xpos_obs / xinc)\n",
    "            obs_nr = i + j * obs_grid_nx\n",
    "            imin = max(I - irange, 0)\n",
    "            imax = min(I + irange + 1, param_grid_nx)\n",
    "            imin_selected = max(-irange, imin - I) + irange\n",
    "            imax_selected = min(irange + 1, imax - I) + irange\n",
    "            # print(f\"{imin=}\")\n",
    "            # print(f\"{imax=}\")\n",
    "            # print(f\"{jmin=}\")\n",
    "            # print(f\"{jmax=}\")\n",
    "\n",
    "            # print(f\"{imin_selected=}\")\n",
    "            # print(f\"{imax_selected=}\")\n",
    "            # print(f\"{jmin_selected=}\")\n",
    "            # print(f\"{jmax_selected=}\")\n",
    "\n",
    "            selected_param_2d[:, :] = False\n",
    "            selected_param_2d[imin:imax, jmin:jmax] = True\n",
    "            selected_param = selected_param_2d.flatten(order=\"F\")\n",
    "            # print(f\"{selected_param_2d=}\")\n",
    "\n",
    "            selected_scaling_factors_2d = scaling_factor_template[\n",
    "                imin_selected:imax_selected, jmin_selected:jmax_selected\n",
    "            ]\n",
    "            # print(f\"{selected_scaling_factors_2d=}\")\n",
    "            selected_scaling_factors = selected_scaling_factors_2d.flatten(order=\"F\")\n",
    "            # print(f\"shape selected_param:  {selected_param.shape}\")\n",
    "            # print(f\"shape selected_scaling_factors:  {selected_scaling_factors.shape}\")\n",
    "            rho_for_one_layer[selected_param, obs_nr] = selected_scaling_factors\n",
    "\n",
    "    return rho_for_one_layer\n",
    "\n",
    "\n",
    "def define_example_observation_field(\n",
    "    grid_xlength: float,\n",
    "    grid_ylength: float,\n",
    "    obs_grid_nx: int,\n",
    "    obs_grid_ny: int,\n",
    ") -> np.ndarray:\n",
    "    # Define observation values for the observation grid\n",
    "    nobs = obs_grid_nx * obs_grid_ny\n",
    "    obs_xinc = grid_xlength / obs_grid_nx\n",
    "    obs_yinc = grid_ylength / obs_grid_ny\n",
    "    print(f\"Observation distance in x direction: {obs_xinc}\")\n",
    "    print(f\"Observation distance in y direction: {obs_yinc}\")\n",
    "    print(f\"obs_grid_nx: {obs_grid_nx}\")\n",
    "    print(f\"obs_grid_ny: {obs_grid_ny}\")\n",
    "\n",
    "    true_observations = np.zeros(nobs, dtype=np.float32)\n",
    "    obs_value_inc_i = 0.45 / (obs_grid_nx - 1)\n",
    "    obs_value_inc_j = 0.45 / (obs_grid_ny - 1)\n",
    "    print(f\"Define observation values (Use a spatial trend). Number of obs = {nobs}\")\n",
    "    obs_nr = 0\n",
    "    for j in range(obs_grid_ny):\n",
    "        for i in range(obs_grid_nx):\n",
    "            true_observations[obs_nr] = 0.1 + obs_value_inc_i * i + obs_value_inc_j * j\n",
    "            obs_nr += 1\n",
    "    return true_observations\n",
    "\n",
    "\n",
    "def obs_error_covariance(\n",
    "    obs_error_std: float,\n",
    "    obs_grid_nx: int,\n",
    "    obs_grid_ny: int,\n",
    "    grid_xlength: float = 0,\n",
    "    grid_ylength: float = 0,\n",
    "    use_obs_correlations: bool = False,\n",
    "    obs_correlation_length_x: float = 0.0,\n",
    "    obs_correlation_length_y: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Define observation covariance matrix.\n",
    "    Return covariance matrix of observations. Default is diagonal covariance.\n",
    "    \"\"\"\n",
    "    print(f\"Use correlated observations: {use_obs_correlations}\")\n",
    "    nobs = obs_grid_nx * obs_grid_ny\n",
    "    obs_error_var = obs_error_std * obs_error_std\n",
    "    # Correlated obs\n",
    "    obs_variances = np.ones(nobs, dtype=np.float64)\n",
    "    obs_variances = obs_error_var * obs_variances\n",
    "    if use_obs_correlations:\n",
    "        C_D = np.diag(obs_variances)\n",
    "        power = 1.85\n",
    "        print(\"Define spatial correlation between observation errors.\")\n",
    "        print(f\"Obs correlation length in x = {obs_correlation_length_x}\")\n",
    "        print(f\"Obs correlation length in y = {obs_correlation_length_y}\")\n",
    "        print(\n",
    "            \"Obs correlation length in number of observation distances in x direction =\"\n",
    "            f\"{int(obs_correlation_length_x / obs_grid_nx)}\"\n",
    "        )\n",
    "        print(\n",
    "            \"Obs correlation length in number of observation distances in y direction =\"\n",
    "            f\"{int(obs_correlation_length_y / obs_grid_ny)}\"\n",
    "        )\n",
    "        print(\n",
    "            \"Spatial correlation defined by correlation function exp(-3*d^power)with \"\n",
    "            f\" power: {power} and d is normalized distance\"\n",
    "        )\n",
    "        xinc_obs = grid_xlength / obs_grid_nx\n",
    "        yinc_obs = grid_ylength / obs_grid_ny\n",
    "        for j1 in range(obs_grid_ny):\n",
    "            ypos1 = (j1 + 0.5) * yinc_obs\n",
    "            for i1 in range(obs_grid_nx):\n",
    "                obs_nr1 = i1 + j1 * obs_grid_nx\n",
    "                xpos1 = (i1 + 0.5) * xinc_obs\n",
    "                for j2 in range(obs_grid_ny):\n",
    "                    ypos2 = (j2 + 0.5) * yinc_obs\n",
    "                    for i2 in range(obs_grid_nx):\n",
    "                        obs_nr2 = i2 + j2 * obs_grid_nx\n",
    "                        xpos2 = (i2 + 0.5) * xinc_obs\n",
    "                        dx = xpos1 - xpos2\n",
    "                        dy = ypos1 - ypos2\n",
    "                        d = math.sqrt(\n",
    "                            (dx / obs_correlation_length_y) ** 2\n",
    "                            + (dy / obs_correlation_length_y) ** 2\n",
    "                        )\n",
    "                        corr = math.exp(-3.0 * (math.pow(d, power)))\n",
    "                        C_D[obs_nr1, obs_nr2] = obs_error_var * corr\n",
    "                        C_D[obs_nr2, obs_nr1] = C_D[obs_nr1, obs_nr2]\n",
    "        return C_D\n",
    "    return obs_variances\n",
    "\n",
    "\n",
    "def monitor_performance(func):\n",
    "    \"\"\"Decorator to monitor time only\"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        print(f\"Function {func.__name__}:\")\n",
    "        print(f\"  Total time: {end_time - start_time:.2f}s\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def run_update(\n",
    "    X_prior: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    rho_one_layer: np.ndarray,\n",
    "    nparam_total: int,\n",
    "    nreal: int,\n",
    "    nobs: int,\n",
    "    nbatch: int,\n",
    "    nlayer_per_batch: int,\n",
    "    nlayer_last_batch: int,\n",
    "    nparam_per_layer: int,\n",
    "    smoother_object,\n",
    "    truncation: float = 0.99,\n",
    "    use_localization: bool = True,\n",
    "    use_preparation_for_batch_assimilation: bool = True,\n",
    "):\n",
    "    assimilate = monitor_performance(smoother_object.assimilate)\n",
    "    print(\"Start running update batch by batch of field parameters with localization\")\n",
    "    print(\"Prepare for distance-based update\")\n",
    "    if use_localization:\n",
    "        prepare_assimilation = monitor_performance(smoother_object.prepare_assimilation)\n",
    "        assimilate_batch = monitor_performance(smoother_object.assimilate_batch)\n",
    "        prepare_assimilation(Y, truncation=truncation)\n",
    "\n",
    "    X_posterior = np.zeros((nparam_total, nreal), dtype=np.float32)\n",
    "    batch_param_end = 0\n",
    "    for batch_nr in range(nbatch):\n",
    "        print(f\"Start batch number: {batch_nr}\")\n",
    "\n",
    "        nparam_per_batch = nparam_per_layer * nlayer_per_batch\n",
    "        rho_batch = np.zeros((nparam_per_batch, nobs), dtype=np.float32)\n",
    "        batch_param_start = batch_nr * nparam_per_batch\n",
    "        batch_param_end = batch_param_start + nparam_per_batch\n",
    "        # Since localization only use lateral distance\n",
    "        # rho for one layer is copied into all the Nlayer_per_batch\n",
    "        for layer in range(nlayer_per_batch):\n",
    "            from_param = layer * nparam_per_layer\n",
    "            to_param = from_param + nparam_per_layer\n",
    "            rho_batch[from_param:to_param, :] = rho_one_layer[:]\n",
    "\n",
    "        X_prior_batch = X_prior[batch_param_start:batch_param_end, :]\n",
    "        if use_localization:\n",
    "            print(\" Assimilate using distance-based localisation\")\n",
    "            if use_preparation_for_batch_assimilation:\n",
    "                X_posterior_batch = assimilate_batch(\n",
    "                    X_batch=X_prior_batch, Y=Y, rho_batch=rho_batch\n",
    "                )\n",
    "            else:\n",
    "                X_posterior_batch = assimilate(\n",
    "                    X=X_prior_batch, Y=Y, rho=rho_batch, truncation=0.999\n",
    "                )\n",
    "            X_posterior[batch_param_start:batch_param_end, :] = X_posterior_batch\n",
    "        else:\n",
    "            print(\" Assimilate using one iteration of ESMDA\")\n",
    "            X_posterior_batch = smoother_object.assimilate(X=X_prior_batch, Y=Y)\n",
    "            X_posterior[batch_param_start:batch_param_end, :] = X_posterior_batch\n",
    "\n",
    "    if nlayer_last_batch > 0:\n",
    "        print(f\"Start batch number: {nbatch}\")\n",
    "\n",
    "        nparam_last_batch = nlayer_last_batch * nparam_per_layer\n",
    "        rho_batch = np.zeros((nparam_last_batch, nobs), dtype=np.float32)\n",
    "        batch_param_start = batch_param_end\n",
    "        batch_param_end = nparam_total\n",
    "        # Since localization only use lateral distance\n",
    "        # rho for one layer is copied into all the Nlayer_per_batch\n",
    "        for layer in range(nlayer_last_batch):\n",
    "            from_param = layer * nparam_per_layer\n",
    "            to_param = from_param + nparam_per_layer\n",
    "            rho_batch[from_param:to_param, :] = rho_one_layer[:]\n",
    "\n",
    "        X_prior_batch = X_prior[batch_param_start:batch_param_end, :]\n",
    "        if use_localization:\n",
    "            print(\" Assimilate using distance-based localisation\")\n",
    "            if use_preparation_for_batch_assimilation:\n",
    "                X_posterior_batch = assimilate_batch(\n",
    "                    X_batch=X_prior_batch, Y=Y, rho_batch=rho_batch\n",
    "                )\n",
    "            else:\n",
    "                X_posterior_batch = assimilate(\n",
    "                    X=X_prior_batch, Y=Y, rho=rho_batch, truncation=0.999\n",
    "                )\n",
    "\n",
    "            X_posterior[batch_param_start:batch_param_end, :] = X_posterior_batch\n",
    "        else:\n",
    "            print(\" Assimilate using one iteration of ESMDA\")\n",
    "            X_posterior_batch = smoother_object.assimilate(X=X_prior_batch, Y=Y)\n",
    "            X_posterior[batch_param_start:batch_param_end, :] = X_posterior_batch\n",
    "\n",
    "    return X_posterior\n",
    "\n",
    "\n",
    "# --- Main ---\n",
    "# Drogon size nx = 92, ny = 146, nz=66\n",
    "# Large field size  ERTBOX size: nx = 412 ny = 714 nz = 60\n",
    "Mx = 9  # Number of field parameters values in one coarse grid cell\n",
    "My = 9\n",
    "Mz = 60\n",
    "Kx = 50  # Dimensions of the 3D upscaled grid\n",
    "Ky = 80\n",
    "Kz = 1\n",
    "\n",
    "# Mx = 2  # Number of field parameters values in one coarse grid cell\n",
    "# My = 2\n",
    "# Mz = 66\n",
    "# Kx = 92 # Dimensions of the 3D upscaled grid\n",
    "# Ky = 146\n",
    "# Kz = 1\n",
    "\n",
    "Nx = Mx * Kx  # Dimensions of the 3D parameter grid\n",
    "Ny = My * Ky\n",
    "Nz = Mz * Kz\n",
    "Nlayer_per_batch = 3\n",
    "Nbatch = int(Nz / Nlayer_per_batch)\n",
    "Nlayer_last_batch = Nz - Nlayer_per_batch * Nbatch\n",
    "N_m = Nx * Ny * Nz\n",
    "Xinc = 75.0  # Field parameter grid cell size\n",
    "Yinc = 75.0\n",
    "Zinc = 1.0\n",
    "Xinc_upscaled = Xinc * Mx  # Coarse scale grid cell size\n",
    "Yinc_upscaled = Yinc * My\n",
    "Zinc_upscaled = Zinc * Mz\n",
    "Rotation = 0.0  # Rotation of the field parameter grid\n",
    "Xorigo = 1000.0  # rotation point in global coordinates\n",
    "Yorigo = 1200.0\n",
    "Zorigo = 2000.0\n",
    "Variotype = \"gen_exponential\"  # Spatial covariance of field parameters\n",
    "Main_range = Xinc * Nx * 0.1\n",
    "Perp_range = Yinc * Ny * 0.1\n",
    "Vert_range = Zinc * Nz * 0.1\n",
    "Azimuth = 0.0\n",
    "Dip = 0.0\n",
    "Power = 1.9  # Used in correlation functions\n",
    "N_e = 100  # Number of realizations\n",
    "\n",
    "Obs_error_std = 0.05  # Observation error standard deviation\n",
    "Use_obs_correlations = False\n",
    "Obs_correlation_length_x = Main_range\n",
    "Obs_correlation_length_y = Perp_range\n",
    "\n",
    "# Localization range parameters\n",
    "local_tapering_function_name = \"gaussian\"\n",
    "x_loc_range = Main_range\n",
    "y_loc_range = Perp_range\n",
    "loc_ellipse_rotation = 0.0\n",
    "cutoff_value = 0.01\n",
    "print(f\"Field size (nx, ny, nz) = ({Nx},{Ny},{Nz})\")\n",
    "print(f\"Localization x-range: {x_loc_range}\")\n",
    "print(f\"Localization y-range: {y_loc_range}\")\n",
    "print(f\"Localization ellipse rotation angle: {loc_ellipse_rotation}\")\n",
    "\n",
    "# --- 1. Generate Initial Ensemble ---\n",
    "\n",
    "# Draw prior realizations of the field parameters\n",
    "variogram = sim.variogram(\n",
    "    Variotype, Main_range, Perp_range, Vert_range, Azimuth, Dip, Power\n",
    ")\n",
    "print(\"Simulate prior fields\")\n",
    "X_prior = simulate_realizations(N_e, variogram, Nx, Ny, Nz, Xinc, Yinc, Zinc, seed)\n",
    "\n",
    "\n",
    "# --- 2. Define observations ---\n",
    "# Observation field (e.g seismic on regular 2D grid with\n",
    "# grid size and orientation as grid for field parameters,\n",
    "# but in general with different grid increments.\n",
    "grid_xlength = Xinc * Nx\n",
    "grid_ylength = Yinc * Ny\n",
    "obs_grid_nx = (\n",
    "    Kx  # Number of grid cells in x direction of observation field (e.g. seismic)\n",
    ")\n",
    "obs_grid_ny = (\n",
    "    Ky  # Number of grid cells in y direction of observation field (e.g. seismic)\n",
    ")\n",
    "nobs = obs_grid_nx * obs_grid_ny  # Assume one active obs per observation grid cell\n",
    "observation_field = define_example_observation_field(\n",
    "    grid_xlength, grid_ylength, obs_grid_nx, obs_grid_ny\n",
    ")\n",
    "\n",
    "C_D = obs_error_covariance(\n",
    "    Obs_error_std,\n",
    "    obs_grid_nx,\n",
    "    obs_grid_ny,\n",
    "    grid_xlength,\n",
    "    grid_ylength,\n",
    "    Use_obs_correlations,\n",
    "    Obs_correlation_length_x,\n",
    "    Obs_correlation_length_y,\n",
    ")\n",
    "\n",
    "# Initialize smoothers with the current run's seeded RNG\n",
    "rng = np.random.default_rng(seed)\n",
    "alpha_i = 1\n",
    "\n",
    "\n",
    "nparam_per_layer = Nx * Ny\n",
    "print(\"Calculate rho for one field parameter grid layer\")\n",
    "calculate_rho_for_2d_obs_field = monitor_performance(calculate_rho_for_2d_obs_field)\n",
    "\n",
    "rho_one_layer = calculate_rho_for_2d_obs_field(\n",
    "    grid_xlength,\n",
    "    grid_ylength,\n",
    "    Nx,\n",
    "    Ny,\n",
    "    obs_grid_nx,\n",
    "    obs_grid_ny,\n",
    "    x_loc_range,\n",
    "    y_loc_range,\n",
    "    loc_ellipse_rotation,\n",
    "    local_tapering_function_name,\n",
    "    cutoff_value=cutoff_value,\n",
    ")\n",
    "calculate_rho_for_2d_obs_field_version2 = monitor_performance(\n",
    "    calculate_rho_for_2d_obs_field_version2\n",
    ")\n",
    "rho_one_layer = calculate_rho_for_2d_obs_field_version2(\n",
    "    grid_xlength,\n",
    "    grid_ylength,\n",
    "    Nx,\n",
    "    Ny,\n",
    "    obs_grid_nx,\n",
    "    obs_grid_ny,\n",
    "    x_loc_range,\n",
    "    y_loc_range,\n",
    "    loc_ellipse_rotation,\n",
    "    local_tapering_function_name,\n",
    "    cutoff_value=cutoff_value,\n",
    ")\n",
    "# diff_rho_one_layer = rho_one_layer1 - rho_one_layer2\n",
    "# delta_rho_mean =np.mean(diff_rho_one_layer)\n",
    "# delta_rho_std = np.std(diff_rho_one_layer)\n",
    "# print(f\"Mean of diff between rho_one_layer_for two methods: {delta_rho_mean}\")\n",
    "# print(f\"Std of diff between rho_one_layer_for two methods: {delta_rho_std}\")\n",
    "# print(f\"max_diff: {np.max(diff_rho_one_layer)}\")\n",
    "# print(f\"min_diff: {np.min(diff_rho_one_layer)}\")\n",
    "# rho_one_layer = rho_one_layer2\n",
    "\n",
    "# Forward model applied to each realization\n",
    "# In this case arithmetic upscaling of field parameter intervals of size\n",
    "# [Mx, My, Mz] into 1 coarse grid cell. The values of the coarse grid cells\n",
    "# are predictions of what we define as observations in this example.\n",
    "Y = forward_model(X_prior, N_e, Nx, Ny, Nz, obs_grid_nx, obs_grid_ny, 1)\n",
    "\n",
    "print(f\"Initialize smoother for distance based localisation for alpha = {alpha_i}:\")\n",
    "esmda_distance = DistanceESMDA(\n",
    "    covariance=C_D, observations=observation_field, alpha=alpha_i, seed=rng\n",
    ")\n",
    "\n",
    "run_update = monitor_performance(run_update)\n",
    "X_posterior = run_update(\n",
    "    X_prior,\n",
    "    Y,\n",
    "    rho_one_layer,\n",
    "    N_m,\n",
    "    N_e,\n",
    "    nobs,\n",
    "    Nbatch,\n",
    "    Nlayer_per_batch,\n",
    "    Nlayer_last_batch,\n",
    "    nparam_per_layer,\n",
    "    esmda_distance,\n",
    "    use_localization=True,\n",
    "    use_preparation_for_batch_assimilation=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Initialize smoother for global esmda for alpha = {alpha_i}:\")\n",
    "# Workaround since ESMDA counts number of calls on assimilate and\n",
    "# but here we want to run it once (only one alpha value, one iteration)\n",
    "# but it is called multiple times due to the number of batches\n",
    "alpha = np.zeros((Nbatch + 1), dtype=np.float32)\n",
    "alpha[:] = alpha_i\n",
    "\n",
    "esmda_global = ESMDA(\n",
    "    covariance=C_D, observations=observation_field, alpha=alpha, seed=rng\n",
    ")\n",
    "\n",
    "X_posterior_global = run_update(\n",
    "    X_prior,\n",
    "    Y,\n",
    "    rho_one_layer,\n",
    "    N_m,\n",
    "    N_e,\n",
    "    nobs,\n",
    "    Nbatch,\n",
    "    Nlayer_per_batch,\n",
    "    Nlayer_last_batch,\n",
    "    nparam_per_layer,\n",
    "    esmda_global,\n",
    "    use_localization=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate misfit\n",
    "observation_field_all_real = np.zeros((nobs, N_e))\n",
    "for n in range(N_e):\n",
    "    observation_field_all_real[:, n] = observation_field[:]\n",
    "\n",
    "tmp_diff = Y - observation_field_all_real\n",
    "misfit_prior = np.sqrt(np.mean(tmp_diff * tmp_diff, axis=1))\n",
    "misfit_prior_2d = misfit_prior.reshape(obs_grid_ny, obs_grid_nx)\n",
    "obs_field_2d = observation_field.reshape(obs_grid_ny, obs_grid_nx)\n",
    "\n",
    "print(\"Mean and stdev of prior fields\")\n",
    "prior_mean = np.mean(X_prior, axis=1)\n",
    "prior_std = np.std(X_prior, axis=1)\n",
    "\n",
    "print(\"Mean and stdev of fields updated with localisation\")\n",
    "posterior_mean = np.mean(X_posterior, axis=1)\n",
    "posterior_std = np.std(X_posterior, axis=1)\n",
    "\n",
    "print(\"Mean and stdev of fields updated without localisation\")\n",
    "posterior_global_mean = np.mean(X_posterior_global, axis=1)\n",
    "posterior_global_std = np.std(X_posterior_global, axis=1)\n",
    "\n",
    "# Converted to 3D array\n",
    "prior_mean_3d = prior_mean.reshape((Nz, Ny, Nx))\n",
    "prior_std_3d = prior_std.reshape((Nz, Ny, Nx))\n",
    "\n",
    "update_localized_3d = (posterior_mean - prior_mean).reshape((Nz, Ny, Nx))\n",
    "update_localized_std_3d = posterior_std.reshape((Nz, Ny, Nx))\n",
    "\n",
    "update_global_3d = (posterior_global_mean - prior_mean).reshape((Nz, Ny, Nx))\n",
    "update_global_std_3d = posterior_global_std.reshape((Nz, Ny, Nx))\n",
    "\n",
    "\n",
    "print(\"Run forward model on updated fields with localization\")\n",
    "Ypost = forward_model(X_posterior, N_e, Nx, Ny, Nz, Kx, Ky, Kz)\n",
    "\n",
    "tmp_diff = Ypost - observation_field_all_real\n",
    "misfit_post = np.sqrt(np.mean(tmp_diff * tmp_diff, axis=1))\n",
    "misfit_post_2d = misfit_post.reshape(obs_grid_ny, obs_grid_nx)\n",
    "\n",
    "\n",
    "# --- Slices of the Update Fields using global update ---\n",
    "#     # Find a single, symmetric color scale for both update plots\n",
    "update_max_abs = np.max([np.abs(update_localized_3d), np.abs(prior_mean_3d)])\n",
    "vmin_update, vmax_update = -update_max_abs, update_max_abs\n",
    "\n",
    "std_vmax = np.max(update_localized_std_3d)\n",
    "std_vmax_global = np.max(update_global_std_3d)\n",
    "std_vmax_prior = np.max(prior_std_3d)\n",
    "std_mean = np.mean(update_localized_std_3d)\n",
    "std_mean_global = np.mean(update_global_std_3d)\n",
    "std_mean_prior = np.mean(prior_std_3d)\n",
    "std_local = max(std_vmax, std_vmax_prior)\n",
    "rms_misfit_prior = np.sqrt(np.mean(misfit_prior_2d * misfit_prior_2d))\n",
    "rms_misfit_post = np.sqrt(np.mean(misfit_post_2d * misfit_post_2d))\n",
    "\n",
    "print(f\"Max std for prior:  {std_vmax_prior}\")\n",
    "print(f\"Max Std without localization:  {std_vmax_global}\")\n",
    "print(f\"Max Std with localization:  {std_vmax}\")\n",
    "print(f\"Mean Std for prior:  {std_mean_prior}\")\n",
    "print(f\"Mean Std without localization:  {std_mean_global}\")\n",
    "print(f\"Mean Std with localization:  {std_mean}\")\n",
    "print(f\"RootMeanSquare misfit prior: {rms_misfit_prior}\")\n",
    "print(f\"RootMeanSquare misfit posterior: {rms_misfit_post}\")\n",
    "\n",
    "\n",
    "# Cross sections\n",
    "k_indx = int(Nz / 2)\n",
    "i_indx = int(Nx / 2)\n",
    "j_indx = int(Ny / 2)\n",
    "\n",
    "std_vmax = np.max(update_localized_std_3d)\n",
    "std_vmax_global = np.max(update_global_std_3d)\n",
    "std_vmax_prior = np.max(prior_std_3d)\n",
    "\n",
    "# --- Create 3D Cross-Sectional Plots ---\n",
    "fig, axes = plt.subplots(9, 3, figsize=(15, 18))\n",
    "fig.suptitle(\"3D Cross-Sectional Views of Localization and Updates\", fontsize=14)\n",
    "\n",
    "row_number = 0\n",
    "\n",
    "# Localized Update\n",
    "im_update = axes[row_number, 0].imshow(\n",
    "    update_localized_3d[k_indx, :, :],\n",
    "    cmap=\"gist_rainbow\",\n",
    "    vmin=vmin_update,\n",
    "    vmax=vmax_update,\n",
    ")\n",
    "axes[row_number, 0].set_title(f\"Local Update - XY Slice at k = {k_indx}\")\n",
    "\n",
    "axes[row_number, 1].imshow(\n",
    "    update_localized_3d[:, j_indx, :],\n",
    "    cmap=\"gist_rainbow\",\n",
    "    vmin=vmin_update,\n",
    "    vmax=vmax_update,\n",
    ")\n",
    "axes[row_number, 1].set_title(f\"Local Update - XZ Slice at j = {j_indx}\")\n",
    "\n",
    "axes[row_number, 2].imshow(\n",
    "    update_localized_3d[:, :, i_indx],\n",
    "    cmap=\"gist_rainbow\",\n",
    "    vmin=vmin_update,\n",
    "    vmax=vmax_update,\n",
    ")\n",
    "axes[row_number, 2].set_title(f\"Local Update - YZ Slice at i = {i_indx}\")\n",
    "\n",
    "fig.colorbar(\n",
    "    im_update, ax=axes[row_number, :], location=\"right\", shrink=0.8, label=\"Values\"\n",
    ")\n",
    "row_number += 1\n",
    "\n",
    "# --- Slices of the Update Fields using global update ---\n",
    "\n",
    "# Prior\n",
    "im_prior = axes[row_number, 0].imshow(\n",
    "    prior_mean_3d[k_indx, :, :], cmap=\"gist_rainbow\", vmin=vmin_update, vmax=vmax_update\n",
    ")\n",
    "axes[row_number, 0].set_title(f\"Prior - XY Slice at k = {k_indx}\")\n",
    "\n",
    "axes[row_number, 1].imshow(\n",
    "    prior_mean_3d[:, j_indx, :], cmap=\"gist_rainbow\", vmin=vmin_update, vmax=vmax_update\n",
    ")\n",
    "axes[row_number, 1].set_title(f\"Prior - XZ Slice at j = {j_indx}\")\n",
    "\n",
    "axes[row_number, 2].imshow(\n",
    "    prior_mean_3d[:, :, i_indx], cmap=\"gist_rainbow\", vmin=vmin_update, vmax=vmax_update\n",
    ")\n",
    "axes[row_number, 2].set_title(f\"Prior - YZ Slice at i = {i_indx}\")\n",
    "fig.colorbar(\n",
    "    im_prior, ax=axes[row_number, :], location=\"right\", shrink=0.8, label=\"Values\"\n",
    ")\n",
    "row_number += 1\n",
    "\n",
    "# Global Update\n",
    "im_global = axes[row_number, 0].imshow(\n",
    "    update_global_3d[k_indx, :, :],\n",
    "    cmap=\"gist_rainbow\",\n",
    "    vmin=vmin_update,\n",
    "    vmax=vmax_update,\n",
    ")\n",
    "axes[row_number, 0].set_title(f\"Global Update - XY Slice at k = {k_indx}\")\n",
    "\n",
    "axes[row_number, 1].imshow(\n",
    "    update_global_3d[:, j_indx, :],\n",
    "    cmap=\"gist_rainbow\",\n",
    "    vmin=vmin_update,\n",
    "    vmax=vmax_update,\n",
    ")\n",
    "axes[row_number, 1].set_title(f\"Global Update - XZ Slice at j = {j_indx}\")\n",
    "\n",
    "axes[row_number, 2].imshow(\n",
    "    update_global_3d[:, :, i_indx],\n",
    "    cmap=\"gist_rainbow\",\n",
    "    vmin=vmin_update,\n",
    "    vmax=vmax_update,\n",
    ")\n",
    "axes[row_number, 2].set_title(f\"Global Update - YZ Slice at i = {i_indx}\")\n",
    "fig.colorbar(\n",
    "    im_global, ax=axes[row_number, :], location=\"right\", shrink=0.8, label=\"Values\"\n",
    ")\n",
    "row_number += 1\n",
    "\n",
    "max_std = 1.1\n",
    "# Prior std\n",
    "im_prior_std = axes[row_number, 0].imshow(\n",
    "    prior_std_3d[k_indx, :, :], cmap=\"gist_rainbow\", vmin=0, vmax=max_std\n",
    ")\n",
    "axes[row_number, 0].set_title(f\"Prior Std - XY Slice at k = {k_indx}\")\n",
    "\n",
    "axes[row_number, 1].imshow(\n",
    "    prior_std_3d[:, j_indx, :], cmap=\"gist_rainbow\", vmin=0, vmax=max_std\n",
    ")\n",
    "axes[row_number, 1].set_title(f\"Prior Std - XZ Slice at j = {j_indx}\")\n",
    "\n",
    "axes[row_number, 2].imshow(\n",
    "    prior_std_3d[:, :, i_indx], cmap=\"gist_rainbow\", vmin=0, vmax=max_std\n",
    ")\n",
    "axes[row_number, 2].set_title(f\"Prior Std - YZ Slice at i = {i_indx}\")\n",
    "fig.colorbar(\n",
    "    im_prior_std,\n",
    "    ax=axes[row_number, :],\n",
    "    location=\"right\",\n",
    "    shrink=0.8,\n",
    "    label=\"Std values\",\n",
    ")\n",
    "row_number += 1\n",
    "\n",
    "# Posterior std with localisation\n",
    "im_post_std = axes[row_number, 0].imshow(\n",
    "    update_localized_std_3d[k_indx, :, :], cmap=\"gist_rainbow\", vmin=0, vmax=max_std\n",
    ")\n",
    "axes[row_number, 0].set_title(f\"Local Post Std - XY Slice at k = {k_indx}\")\n",
    "\n",
    "axes[row_number, 1].imshow(\n",
    "    update_localized_std_3d[:, j_indx, :], cmap=\"gist_rainbow\", vmin=0, vmax=max_std\n",
    ")\n",
    "axes[row_number, 1].set_title(f\"Local Post Std - XZ Slice at j = {j_indx}\")\n",
    "\n",
    "axes[row_number, 2].imshow(\n",
    "    update_localized_std_3d[:, :, i_indx], cmap=\"gist_rainbow\", vmin=0, vmax=max_std\n",
    ")\n",
    "axes[row_number, 2].set_title(f\"Local Post Std - YZ Slice at i = {i_indx}\")\n",
    "fig.colorbar(\n",
    "    im_post_std,\n",
    "    ax=axes[row_number, :],\n",
    "    location=\"right\",\n",
    "    shrink=0.8,\n",
    "    label=\"Std values\",\n",
    ")\n",
    "row_number += 1\n",
    "\n",
    "# Posterior std without localisation\n",
    "im_post_global_std = axes[row_number, 0].imshow(\n",
    "    update_global_std_3d[k_indx, :, :], cmap=\"gist_rainbow\", vmin=0.0, vmax=max_std\n",
    ")\n",
    "axes[row_number, 0].set_title(f\"Global Post Std - XY Slice at k = {k_indx}\")\n",
    "\n",
    "axes[row_number, 1].imshow(\n",
    "    update_global_std_3d[:, j_indx, :], cmap=\"gist_rainbow\", vmin=0.0, vmax=max_std\n",
    ")\n",
    "axes[row_number, 1].set_title(f\"Global Post Std - XZ Slice at j = {j_indx}\")\n",
    "\n",
    "axes[row_number, 2].imshow(\n",
    "    update_global_std_3d[:, :, i_indx], cmap=\"gist_rainbow\", vmin=0.0, vmax=max_std\n",
    ")\n",
    "axes[row_number, 2].set_title(f\"Global Post Std - YZ Slice at i = {i_indx}\")\n",
    "fig.colorbar(\n",
    "    im_post_global_std,\n",
    "    ax=axes[row_number, :],\n",
    "    location=\"right\",\n",
    "    shrink=0.8,\n",
    "    label=\"Std values\",\n",
    ")\n",
    "row_number += 1\n",
    "\n",
    "# Observations (upscaled values)\n",
    "im_obs_values = axes[row_number, 0].imshow(\n",
    "    obs_field_2d[:, :], cmap=\"gist_rainbow\", vmin=0.0, vmax=1.0\n",
    ")\n",
    "axes[row_number, 0].set_title(\"Observation field - XY\")\n",
    "fig.colorbar(\n",
    "    im_obs_values,\n",
    "    ax=axes[row_number, :],\n",
    "    location=\"right\",\n",
    "    shrink=0.8,\n",
    "    label=\"Obs values\",\n",
    ")\n",
    "row_number += 1\n",
    "\n",
    "# Misfit between obs and prior prediction of obs\n",
    "im_misfit_prior = axes[row_number, 0].imshow(\n",
    "    misfit_prior_2d[:, :], cmap=\"gist_rainbow\", vmin=0.1, vmax=1.0\n",
    ")\n",
    "axes[row_number, 0].set_title(\"Misfit Prior - XY\")\n",
    "fig.colorbar(\n",
    "    im_misfit_prior,\n",
    "    ax=axes[row_number, :],\n",
    "    location=\"right\",\n",
    "    shrink=0.8,\n",
    "    label=\"Misfit\",\n",
    ")\n",
    "row_number += 1\n",
    "\n",
    "# Misfit between obs and posterior prediction of obs\n",
    "im_misfit_post = axes[row_number, 0].imshow(\n",
    "    misfit_post_2d[:, :], cmap=\"gist_rainbow\", vmin=0.1, vmax=1.0\n",
    ")\n",
    "axes[row_number, 0].set_title(\"Misfit Post - XY\")\n",
    "fig.colorbar(\n",
    "    im_misfit_post,\n",
    "    ax=axes[row_number, :],\n",
    "    location=\"right\",\n",
    "    shrink=0.8,\n",
    "    label=\"Misfit\",\n",
    ")\n",
    "row_number += 1\n",
    "\n",
    "# Hide axis ticks for a cleaner look\n",
    "for ax in axes.flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc580612-af63-46cb-a25e-e0376347ba9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
